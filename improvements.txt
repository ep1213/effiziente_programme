1. Kollisionsauflösungsstrategie auf lineares Sondieren (linear probing) ändern
	- Cachelokalität bei Verkettung der Überläufer schlecht.
	- Haben Cache Miss bei jedem Element der Hashtabelle (inkl.
	  Überläufer).
	- Alternativen: Quadratisches Sondieren, Double Hashing, haben
	  schlechtere Lokalität


2. hashnode size_t keylength an den Anfang des Structs gestetzt
	- Lookup prüft zuerst keylength, ist keylength ganz vorn, spart man
	  eine Instruktion.


3. If-Anweisung bei lookup aus der Schleife kopiert für den Fall, dass wir gleich beim ersten lookup Glück haben
	- Annahme, dass wir im Normalfall keine Kollision haben.
	- Bringt Compiler dazu für Einzelfall zu optimieren.


4. Modulo Operator durch bitweises UND ersetzen
	- UND ist viel billiger.
	- Aber: Compiler hat Modulo mit Konstante erkannt und selbst
	  optimiert.
	  and    $0xfffff,%eax


5. Branch Prediction für den Normalfall (keine Hashkollision) optimieren.
	- Annahme, dass ein IF als Spezialfall gehandhabt wird und eventuell
	  mehr Sprünge braucht.
	- Offenbar wird das auch vom Compiler erkannt.


6. Keine Pointer sondern eine Kopie des hashnode structs in lookup verwenden
	- Einsparen von Pointerdereferenzierungen.
	- Komischerweise sinken dadurch auch die Cache Misses

7. Bulk Lookups
	- Bisher jedes mal Cache Miss bei einem Lookup
	- Lookups gruppieren und jeweilige Hashtable Einträge prefetchen
	- dadurch beim Lookup nurnoch ein oder zwei Cache Misses pro Gruppe

8. Bulk Lookups
	- Weil es letztes Mal so toll funktioniert hat und hier ähnliche
	  Probleme auftreten.

9. Gleiches struct für return werte des bulk lookups verwenden.
	- Muss nicht auf neues array zugreifen -> weniger cache misses
